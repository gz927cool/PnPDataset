## 标准科研级知识图谱构建流程

### 背景与目标

在完成文本到知识三元组的抽取工作后，我们面临一个关键挑战：如何将这些非结构化的文本抽取结果转化为语义可计算、可对齐的知识表达。文本中的实体（如"Accademia Albrizziana"）和关系（如"is_located_in"）具有表述多样性和歧义性，而 Wikidata 提供了全球统一的语义标识体系（Q-ID 用于实体、P-ID 用于关系）。

本流程的核心目标是**建立从原始文本事实到 Wikidata 规范语义标的完整链路**，确保：
- **完整性**：每一条文本抽取的三元组都能找到对应的 Wikidata 表示
- **可追溯性**：任何图谱中的事实都能追溯到原始文本证据
- **可校验性**：对齐过程有明确的置信度和验证记录
- **可复现性**：流程标准化，任何人按相同步骤可得到一致结果
- **可发表性**：方法论透明、数据来源清晰，满足学术发表要求

### 核心转换示例

```
文本抽取事实：
(Accademia Albrizziana, is_located_in, Venice)

Wikidata 语义对齐：
wd:Q1234567  wdt:P131  wd:Q641
```

---

## 数据说明

本流程的输入数据来源于前期文本抽取工作，具体包括：

1. **来源数据**：`data\merged_index_enrich.csv`
   - 这是经过索引构建和 LLM 增强后的结构化数据
   - 包含原始文档标识、文本段落、实体提及等字段

2. **抽取的三元组**：`data\extracted_triplets.csv`
   - 从上述数据中经由 OpenAI/LLM 抽取得到的事实三元组
   - 是本流程的原始输入

落地适配说明：
- `triple_id` 由 `Row_Index` 和 `Index` 组合构成，确保唯一性
- `source_doc` 暂定为数据中的 `Row_Index`，用于定位原始文档
- `source_sentence` 通过 `Row_Index` 从"**来源数据**"中找到来源数据行，格式化拼接各列值后作为来源句子证据

---

## 一、总体流程总览（管线视图）

### 1.1 流程概述

完整处理管线遵循"**实体对齐 → 关系映射 → 验证合并 → 入库溯源**"的递进式设计。管线采用阶段式架构，每个阶段有明确的输入输出约定，支持独立执行和断点续传。

**管线核心链路**：

```
triples_raw.csv (Step 1)
    → 实体消歧与 Wikidata 对齐 (Step 2)
    → 语义关系规范化 (Step 3)
    → 对齐验证 (Step 4)
    → 语义事实层生成 (Step 5)
    → 图谱入库 (Step 6)
    → 溯源与校验层构建 (Step 7)
```

### 1.2 三维信息维护

在整个流程中，我们需要持续维护三种互补的信息维度，它们共同构成了知识图谱的语义骨架：

| 维度 | 含义 | 作用 |
|------|------|------|
| **语义维度** | 知识事实本身 | 核心内容，描述"什么是什么/有什么关系" |
| **来源维度** | 事实来源、抽取证据 | 支撑可追溯性，记录事实从何而来 |
| **对齐维度** | Wikidata 映射与置信度 | 支撑可计算性，将非结构化转为结构化 |

这三种维度贯穿整个流程，在最终的知识表示中仍然保持关联，确保后续分析和论文发表时有据可查。

---

## 二、Step 0：数据预处理（可选）

### 2.1 阶段目标

如果原始抽取的三元组文件格式与本流程定义的 `triples_raw.csv` 不一致，需要先进行格式规范化。

**常见输入格式差异**：
- 缺少 `triple_id` 或 `source_doc` 字段
- `source_sentence` 字段为空或不完整
- 字段分隔符不是逗号

### 2.2 输出文件

**输出文件格式**：`triples_raw.csv`

此文件将作为 Step 1 的正式输入。

---

## 三、Step 1：原始三元组 CSV（输入）

### 3.1 输入文件规范

本阶段定义了管线的**唯一事实起点**。所有后续处理结果都必须能够回溯到这个文件中的某条记录，这种设计确保了流程的可追溯性和可复现性。

**输入文件格式**：`triples_raw.csv`

```csv
triple_id,subject,relation,object,source_doc,source_sentence,confidence
T0001,Accademia Albrizziana,is_located_in,Venice,doc12,"...Accademia Albrizziana was founded in Venice...",0.91
```

### 3.2 字段说明

| 字段名 | 类型 | 说明 | 示例 |
|--------|------|------|------|
| triple_id | string | 唯一事实标识符 | T0001 |
| subject | string | 主语实体原文表述 | Accademia Albrizziana |
| relation | string | 关系原文表述 | is_located_in |
| object | string | 宾语实体原文表述 | Venice |
| source_doc | string | 来源文档标识 | doc12 |
| source_sentence | string | 包含该事实的原始句子（证据） | "...Accademia Albrizziana was founded in Venice..." |
| confidence | float | 抽取置信度，0-1之间 | 0.91 |

### 3.3 数据质量约定

- **唯一性约束**：每个 triple_id 在文件中必须唯一
- **完整性约束**：所有字段均不允许为空（置信度可为0但必须有值）
- **可回溯约束**：source_doc + source_sentence 必须足以让人类读者验证该事实的存在

---

## 四、Step 2：实体标准化与候选生成

### 4.1 阶段目标

本阶段的核心任务是将文本中提到的实体提及（mention）链接到 Wikidata 的规范实体上。由于自然语言表述的多样性，同一个实体可能有多种表述方式（如"Venice"、"威尼斯"、"La Serenissima"等），我们需要通过实体消歧技术找到最可能的 Wikidata Q-ID。

### 4.2 处理流程

1. **实体读取**：读取输入三元组的 subject 和 object 字段
2. **候选搜索**：调用 Wikidata API 或本地知识库，搜索可能的匹配实体
3. **名称规范化**（可选）：使用 LLM 生成标准化的实体名称
4. **候选记录**：保存所有候选实体的 Q-ID、标签和相似度分数

### 4.3 Wikidata API 调用策略

为确保流程的稳定性和效率，我们采用以下 API 调用策略：

- **速率控制**：Wikidata API 有严格的速率限制，建议每秒请求不超过 20-30 次
- **结果缓存**：对已查询的实体建立本地缓存，避免重复请求
- **候选数量**：默认返回 top-5 候选结果，确保覆盖度

### 4.4 输出文件

**输出文件格式**：`entities_candidates.csv`

```csv
triple_id,role,mention,normalized_label,entity_type,candidate_qid,candidate_label,score
T0001,subject,Accademia Albrizziana,Accademia Albrizziana,Institution,Q1234567,Accademia Albrizziana,0.98
T0001,subject,Accademia Albrizziana,Accademia Albrizziana (Palladio),Q1234568,Accademia Albrizziana (Palladio),0.85
T0001,object,Venice,Venice,Place,Q641,Venice,1.00
```

**关键设计说明**：本文件存储的是**所有候选实体**，而非消歧后的单一结果。

- **多候选存储方式**：同一个 `triple_id + role` 组合可能对应多行，每行代表一个候选实体
- **排序规则**：按 `score` 降序排列，最高分候选在先
- **消歧决策**：消歧逻辑在 Step 4（对齐决策与消歧阶段）执行

### 4.5 字段说明

| 字段名 | 说明 |
|--------|------|
| triple_id | 关联的原始三元组 ID |
| role | 实体角色，值为 "subject" 或 "object" |
| mention | 原文中的实体表述形式 |
| normalized_label | 规范化后的实体名称（可与 mention 相同或经 LLM 优化） |
| entity_type | Wikidata 实体类型（Institution、Place、Person、Event 等） |
| candidate_qid | Wikidata 候选实体的 Q-ID |
| candidate_label | 候选实体的规范标签 |
| score | 对齐置信度分数，0-1之间 |

### 4.6 候选生成逻辑

当调用 Wikidata API 搜索实体提及时，可能返回多个候选结果。生成逻辑如下：

1. **候选数量限制**：默认返回 top-5 候选结果
2. **多样性保障**：确保候选来自不同 Wikidata 条目（避免重复）
3. **类型覆盖**：优先包含与关系上下文类型匹配的候选

### 4.7 数据样例：多候选情况

假设 "Milan" 这一实体提及可能对应多个 Wikidata 条目：

```csv
triple_id,role,mention,normalized_label,entity_type,candidate_qid,candidate_label,score
T0100,subject,Milan,Milan,City,Q1741,Milan,0.95
T0100,subject,Milan,Milan,Province,Q1741,Milan,0.92
T0100,subject,Milan,Milan (disambiguation),,Q2498082,Milan,0.45
```

**说明**：
- 前两个候选是同一个 Q-ID（Q1741），分别对应城市和省的类型描述
- 第三个候选是消歧页面，score 较低，通常会被过滤

---

## 五、Step 3：关系语义映射

### 5.1 阶段目标

将文本中表述的关系（如"is_located_in"、"founded_by"）映射到 Wikidata 可能对应的标准属性 P-ID。这一步的目标是**生成关系映射候选集**，而非立即确定唯一的属性，以避免因过早决策而丢失正确的语义解释。

### 5.2 映射策略

我们采用**混合映射策略**，结合规则匹配和 LLM 推断：

1. **预定义映射表**：优先使用人工整理的关系映射字典
2. **规则扩展**：通过同义词库扩展映射覆盖范围
3. **LLM 推断**：对于未命中映射的关系，使用 LLM 进行语义推断

### 5.3 预定义映射表示例

```yaml
# relation_mapping.yaml
is_located_in:
  - property: P131
    label: "located in the administrative territorial entity"
    confidence: 0.95
  - property: P276
    label: "location"
    confidence: 0.85

founded_by:
  - property: P112
    label: "founded by"
    confidence: 0.98

has_member:
  - property: P527
    label: "has member"
    confidence: 0.92
```

### 5.4 LLM 推断提示词模板

对于未在预定义映射表中命中的关系，使用以下 LLM prompt：

```
你是一个知识图谱专家。以下是一个从文本中抽取的关系表述，请将其映射到最可能的 Wikidata 属性。

关系表述：{raw_relation}
上下文：{subject} → {object}

请从以下方面分析：
1. 该关系的语义类型（位置、归属、因果、时间等）
2. 最可能的 Wikidata 属性（提供 P-ID 和 label）
3. 置信度评估（0-1）

输出格式：
PROPERTY: Pxxx
LABEL: xxx
CONFIDENCE: 0.xx
REASONING: xxx
```

### 5.5 输出文件

**输出文件格式**：`relations_mapping.csv`

```csv
triple_id,raw_relation,mapped_property,property_label,property_uri,confidence
T0001,is_located_in,P131,located in the administrative territorial entity,wdt:P131,0.99
T0001,is_located_in,P276,location,wdt:P276,0.85
T0002,has_member,P527,has member,wdt:P527,0.92
```

**关键设计说明**：本文件存储的是**所有候选关系映射**，类似于实体的多候选设计。

- **多映射存储**：同一个 `triple_id` 可能对应多行，表示一个关系表述可能匹配多个 Wikidata 属性
- **排序规则**：按 `confidence` 降序排列
- **最终选择**：在 Step 4（对齐决策阶段）根据类型相容性和置信度选择最佳映射

### 5.6 字段说明

| 字段名 | 说明 |
|--------|------|
| triple_id | 关联的原始三元组 ID |
| raw_relation | 原文关系表述 |
| mapped_property | Wikidata 属性 ID（P131 格式） |
| property_label | 属性的人类可读标签 |
| property_uri | 属性的完整 URI（wdt:P131 格式） |
| confidence | 映射置信度 |

---

## 六、Step 4：智能体对齐决策与消歧 (Agentic Disambiguation)

### 6.1 阶段目标

本阶段是知识图谱构建的决策中心。在 2026 年的技术背景下，采用 **LLM-Based Reasoning (基于大模型的推理)** 策略。

引入 **Disambiguation Agent (消歧智能体)**，利用 LLM 强大的上下文理解能力，模仿人类专家的思维过程，对复杂的候选组合进行判别。

**核心职责**：
1.  **上下文感知**：Agent 同时阅读“原始句子证据”和“Wikidata 候选详情”。
2.  **逻辑推理**：通过 Chain-of-Thought (CoT) 分析，判断哪个候选最符合语境。
3.  **决策输出**：输出唯一的对齐结果，并附带可解释的推理理由（Rationale）。

### 6.2 Agent 工作流设计

**输入数据**：
- **Context**: `source_sentence` (e.g., "...Accademia Albrizziana was founded in Venice...")
- **Candidates**: 
  - Subject Candidates: [Q123 (Institution), Q124 (Book)...]
  - Object Candidates: [Q641 (City), Q642 (Province)...]
  - Relation Candidates: [P131 (Admin Area), P276 (Location)...]

**Agent 推理 Prompt 逻辑**：

```markdown
You are a Knowledge Graph Construction Agent. 
Your task is to identify the correct Wikidata entities and predicates for a given triplet extracted from text.

Input Text: "{source_sentence}"
Extracted Triplet: ({subject}, {relation}, {object})

Candidate Sets:
1. Subject Candidates:
   - Option A: {label} ({desc}) [ID: {qid}]
   - Option B: ...
2. Relation Candidates:
   - Option A: {label} ({desc}) [ID: {pid}]
   - ...
3. Object Candidates:
   - ...

Instructions:
1. Analyze the semantic context of the Input Text.
2. Evaluate which candidate combination makes the most logical sense.
   - CHECK: Do the entity types match the relation's domain/range?
   - CHECK: Is the meaning consistent with the sentence?
3. Select the BEST combination.

Output Format (JSON):
{
  "rationale": "In this context, 'Venice' refers to the city where an academy was founded, not the province...",
  "decision": {
    "subject": "Qxxxx",
    "relation": "Pxxxx",
    "object": "Qxxxx"
  },
  "confidence": 0.95
}
```

### 6.3 混合决策策略 (Hybrid Strategy)

考虑到成本和效率，我们采用分层决策策略：

1.  **Tier 1: 规则快速过滤 (Fast Pass)**
    - 对于候选唯一且置信度极高（>0.98）的简单情况，直接接受，无需调用高级 LLM。
    - 利用 Wikidata 的 `constraints` (如 P131 的 object 必须是行政区) 进行硬过滤。

2.  **Tier 2: Agent 深度推理 (Deep Reasoning)**
    - 对于存在歧义（多个高分候选）或复杂语义的情况，调用 **Disambiguation Agent**。
    - Agent 的决策权重高于传统统计分数。

### 6.4 冲突处理与状态流转

- **Agent Resolved** (`accepted`): Agent 给出明确的高置信度决策。
- **Unresolved Ambiguity** (`conflict`): Agent 认为现有候选均不匹配，或无法区分（需要人工介入）。
- **Hallucination Check**: 引入一个轻量级的 **Critic Agent** 对决策结果进行校验，防止幻觉。

### 6.5 输出文件

**输出文件格式**：`alignment_result.csv`

```csv
triple_id,subject_qid,relation_pid,object_qid,alignment_status,validator,validated_at,notes
T0001,Q1234567,P131,Q641,accepted,auto,2026-01-12,high confidence match
T0002,Q2345678,P112,Q7654321,conflict,auto,2026-01-13,ambiguous: Q234(0.88) vs Q235(0.86)
T0003,,,,,rejected,auto,2026-01-12,no valid entity match
```

### 6.6 字段说明

| 字段名 | 说明 |
|--------|------|
| triple_id | 关联的原始三元组 ID |
| subject_qid | 决策选定的 Subject Q-ID |
| relation_pid | 决策选定的 Relation P-ID |
| object_qid | 决策选定的 Object Q-ID |
| alignment_status | 状态：accepted / conflict / rejected / pending_review |
| validator | 验证者：auto (算法) / human (人工) |
| notes | 决策理由或冲突详情 |


---

## 七、Step 5：生成可溯源语义事实层

### 7.1 阶段目标

将已对齐的三元组转换为标准化的语义 RDF 表示，生成可用于知识图谱分析的中间数据层。这是论文方法论展示的核心数据产出。

### 7.2 URI 规范

采用 Wikidata 标准 URI 格式：

- 实体 URI：`wd:Q1234567`（ Wikidata 实体）
- 属性 URI：`wdt:P131`（ Wikidata 属性，直连）
- 事实 URI：`fact:F0001`（ 自定义事实标识）

### 7.3 输出文件

**输出文件格式**：`facts_semantic.tsv`（使用 TSV 以更好支持大数据量）

```tsv
fact_id	subject_uri	predicate_uri	object_uri	source_triple	confidence
F0001	wd:Q1234567	wdt:P131	wd:Q641	T0001	0.91
F0002	wd:Q2345678	wdt:P112	wd:Q7654321	T0002	0.87
```

### 7.4 字段说明

| 字段名 | 说明 |
|--------|------|
| fact_id | 语义事实唯一标识 |
| subject_uri | 主语实体的标准 URI |
| predicate_uri | 关系的标准 URI |
| object_uri | 宾语实体的标准 URI |
| source_triple | 来源的原始 triple_id |
| confidence | 事实的综合置信度 |

### 7.5 置信度计算

综合置信度按以下公式计算：

```
confidence = 抽取置信度 × 实体对齐置信度 × 关系映射置信度
```

**各因子来源说明**：

| 因子 | 来源文件 | 字段 | 说明 |
|------|----------|------|------|
| 抽取置信度 | triples_raw.csv | confidence | 原始三元组抽取时的置信度 |
| 实体对齐置信度 | entities_candidates.csv | score | 选取的 subject/object 候选的 score |
| 关系映射置信度 | relations_mapping.csv | confidence | 选取的关系映射的 confidence |

**计算方式**：
- 优先使用**几何平均**：`(c1 × c2 × c3)^(1/3)`，任一分量过低会显著拉低整体
- 可选加权平均：为不同因子赋予权重，如 `0.3×c1 + 0.4×c2 + 0.3×c3`


---

## 八、Step 6：构建图谱入库文件

### 8.1 节点去重与构建策略

生成节点文件（nodes.csv）时，需对重复实体进行去重处理，确保每个 URI 只对应一个节点记录。

**去重规则**：
1. **URI 唯一性**：以 Wikidata URI (`wd:Qxxx`) 为主键进行聚合。
2. **属性融合**：
   - **Label/Name**：优先使用 Wikidata 官方 Label；如果缺失，使用出现频率最高的文本 mention。
   - **Type**：保留所有出现过的 Entity Type，去重后以列表形式存储（如 `City;Port`）。
3. **首次出现优先**：保留第一次遇到该实体时的 `source` 信息作为主要来源记录。

### 8.2 节点文件 (nodes.csv)

**输出文件格式**：`nodes.csv`

```csv
id,label,name,qid,entity_type,source
1,Institution,Accademia Albrizziana,Q1234567,educational institution,wikidata
2,Place,Venice,Q641,city,wikidata
3,Person,Andrea Palladio,Q166837,human,wikidata
```

| 字段 | 说明 |
|------|------|
| id | 节点内部 ID（1, 2, 3...） |
| label | 节点类型标签（Institution、Place、Person 等） |
| name | 节点显示名称 |
| qid | Wikidata Q-ID |
| entity_type | Wikidata 实体类型细分 |
| source | 数据来源标识 |

### 8.3 关系文件 (relations.csv)

**输出文件格式**：`relations.csv`

```csv
start_id,relation,end_id,fact_id,source_triple,confidence
1,P131,2,F0001,T0001,0.91
3,P180,1,F0002,T0002,0.88
```

| 字段 | 说明 |
|------|------|
| start_id | 起始节点 ID（引用 nodes.csv 的 id） |
| relation | 关系类型（Wikidata P-ID） |
| end_id | 目标节点 ID |
| fact_id | 关联的事实 ID |
| source_triple | 来源的原始 triple_id |
| confidence | 置信度 |

### 8.4 Neo4j 导入说明

上述 CSV 文件可通过 Neo4j 的 `LOAD CSV` 命令直接导入：

```cypher
// 导入节点
LOAD CSV WITH HEADERS FROM 'file:///nodes.csv' AS row
MERGE (n:Entity {id: toInteger(row.id)})
SET n.label = row.label,
    n.name = row.name,
    n.qid = row.qid,
    n.entity_type = row.entity_type;

// 导入关系
LOAD CSV WITH HEADERS FROM 'file:///relations.csv' AS row
MATCH (s:Entity {id: toInteger(row.start_id)})
MATCH (o:Entity {id: toInteger(row.end_id)})
MERGE (s)-[r:RELATION {type: row.relation}]->(o)
SET r.fact_id = row.fact_id,
    r.source_triple = row.source_triple,
    r.confidence = toFloat(row.confidence);
```

---

## 九、Step 7：溯源与校验模型

### 9.1 溯源图设计

在 Neo4j 中显式建模溯源关系，使得从任意图谱事实可以追溯到原始文本证据：

```cypher
// 核心溯源结构
(:Fact {fact_id: "F0001", confidence: 0.91})
  -[:SUPPORTED_BY {aligned_at: "2026-01-12"}]->
  (:TextTriple {triple_id: "T0001", source_doc: "doc12"})
  -[:EXTRACTED_FROM {sentence: "...Accademia Albrizziana was founded in Venice..."}]->
  (:Document {doc_id: "doc12"})
```

### 9.2 溯源查询示例

**查询 1：追溯事实的文本来源**

```cypher
MATCH (f:Fact {fact_id: "F0001"})-[:SUPPORTED_BY]->(t:TextTriple)
RETURN f, t;
```

**查询 2：验证实体对齐过程**

```cypher
MATCH (f:Fact)-[:HAS_SUBJECT]->(e:EntityCandidate)-[:MATCHED_TO]->(wd: WikidataEntity)
WHERE f.fact_id = "F0001"
RETURN e.confidence, wd.qid;
```

**查询 3：统计各来源的置信度分布**

```cypher
MATCH (f:Fact)-[:SUPPORTED_BY]->(t:TextTriple)
RETURN t.source_doc AS source,
       count(f) AS fact_count,
       avg(f.confidence) AS avg_confidence
ORDER BY avg_confidence DESC;
```

### 9.3 Agentic 校验与自修正 (Self-Correction)

引入 **Reflexion (反思)** 机制，利用溯源图实现自动化校验和修正：

1.  **一致性校验 (Consistency Agent)**：
    - 周期性扫描图谱，检查同一实体在不同事实中的类型是否冲突。
    - 示例：如果 `Q123` 在 Fact A 中被当作 Person，在 Fact B 中被当作 Location，Agent 会触发报警并启动重新消歧。

2.  **悬空节点修复 (Orphan Healing)**：
    - 检查无来源的节点，尝试调用 Search Agent 重新寻找证据或合并节点。

3.  **准确性验证**：
    - 随机抽取样本，由高级模型（如 GPT-4o 或同级）作为 Validator 进行“双盲测试”，计算对齐准确率（Precision）。

---

## 十、异常处理与质量保障

### 10.1 常见异常类型

| 异常类型 | 处理策略 |
|----------|----------|
| 实体未找到候选 | 标记为 pending_review，保留原文表述 |
| 关系未找到映射 | 标记为 pending_review，使用 LLM 推断 |
| 多候选实体冲突 | 选择最高分，记录所有候选 |
| 类型不匹配 | 降级置信度或标记为 rejected |
| API 超时/限流 | 记录断点，使用缓存重试 |

### 10.2 断点续传机制

大文件处理时支持断点续传：

1. 每个阶段输出 checkpoint 文件，记录已处理的 triple_id 列表
2. 程序中断后，可从 checkpoint 继续处理
3. checkpoint 格式示例：

```json
{
  "step": 2,
  "last_processed_id": "T0512",
  "timestamp": "2026-01-12T10:30:00Z",
  "total_processed": 512,
  "total_records": 1000
}
```

### 10.3 质量评估指标

| 指标 | 计算方法 | 目标值 |
|------|----------|--------|
| 实体对齐覆盖率 | 对齐成功数 / 总实体数 | > 85% |
| 关系映射覆盖率 | 映射成功数 / 总关系数 | > 90% |
| 自动接受率 | 自动接受数 / 总处理数 | > 70% |
| 人工审核率 | 待审核数 / 总处理数 | < 30% |
| 抽样准确率 | 人工验证正确数 / 抽样数 | > 95% |

### 9.4 置信度阈值设定

本流程涉及多个置信度阈值，需根据实际数据分布进行调整：

| 阈值名称 | 默认值 | 作用 | 调整建议 |
|----------|--------|------|----------|
| entity_score_threshold | 0.7 | 实体对齐自动接受阈值 | 数据质量高时可降低 |
| relation_confidence_threshold | 0.8 | 关系映射自动接受阈值 | 根据映射表覆盖度调整 |
| final_confidence_threshold | 0.6 | 事实最终置信度阈值 | 影响自动接受率 |
| low_quality_review_threshold | 0.5 | 低于此值强制人工审核 | 建议不修改 |

**阈值调整流程**：

1. **初始运行**：使用默认阈值，统计各阶段的置信度分布
2. **分布分析**：绘制 histogram，观察置信度分布是否双峰
3. **阈值优化**：将阈值调整到双峰之间的低谷处
4. **验证测试**：抽样验证优化后的阈值效果

---

## 十、成果预期

| 能力 | 实现方式 | 验证方法 |
|------|----------|----------|
| **可追溯** | 每条 fact → triple_id → source_doc/sentence | 溯源图查询 |
| **可校验** | 每次对齐有 confidence、validator、timestamp 记录 | 校验脚本 |
| **可复现** | 每步文件输入输出固定，代码版本控制 | 重新运行管线 |
| **可发表** | 数据来源清晰、方法论透明、统计指标完备 | 论文附录 |
| **可扩展** | 支持链接预测、新实体发现、新关系扩展 | 图算法应用 |

---

## 附录 A：文件流转总览（含 Step 间数据流）

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Step 0: 数据预处理（可选）                          │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ 输入: extracted_triplets.csv                                          │    │
│  │ 处理: 字段规范化、triple_id 生成、source_sentence 构建                │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                              Step 1: 规范化输入                              │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ triples_raw.csv                                                       │    │
│  │ triple_id, subject, relation, object, source_doc, source_sentence,  │    │
│  │                      confidence                                      │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                              Step 2: 实体对齐                                │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ entities_candidates.csv                                               │    │
│  │ triple_id, role, mention, candidate_qid, score, ...                 │    │
│  │ (多候选存储，同一 triple_id+role 可有多行)                            │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                              Step 3: 关系映射                                │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ relations_mapping.csv                                                 │    │
│  │ triple_id, raw_relation, mapped_property, confidence, ...           │    │
│  │ (多映射存储，同一 triple_id 可有多行)                                  │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                 ┌────────────────────┼────────────────────┐
                 │                    │                    │
                 ▼                    ▼                    ▼
┌─────────────────────┐  ┌─────────────────────┐  ┌─────────────────────┐
│  合并实体候选        │  │  合并关系映射        │  │  类型相容性校验      │
│  (按 score 排序)     │  │  (按 confidence)    │  │  (Domain/Range)     │
└─────────────────────┘  └─────────────────────┘  └─────────────────────┘
                 │                    │                    │
                 └────────────────────┼────────────────────┘
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          Step 4: 对齐决策与验证                              │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ alignment_result.csv                                                  │    │
│  │ triple_id, subject_qid, relation_pid, object_qid, status, ...       │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          Step 5: 语义事实层                                  │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │ facts_semantic.tsv                                                    │    │
│  │ fact_id, subject_uri, predicate_uri, object_uri, confidence         │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          Step 6-7: 图谱入库                                  │
│  ┌─────────────────────┐  ┌─────────────────────┐  ┌───────────────────┐   │
│  │ nodes.csv           │  │ relations.csv       │  │ provenance_graph  │   │
│  │ (去重后的实体节点)   │  │ (带溯源信息的关系)   │  │ (溯源图 CQL)      │   │
│  └─────────────────────┘  └─────────────────────┘  └───────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 附录 B：技术栈建议

| 层级 | 推荐工具 |
|------|----------|
| 数据处理 | Python 3.12+, pandas |
| Wikidata API | wikidata-sdk, SPARQL  endpoint |
| LLM | OpenAI API (GPT-4) / 本地模型 |
| 图数据库 | Neo4j 5.x |
| 版本控制 | Git + DVC (数据版本) |
| 智能体框架 | LangChain v1.x|
| 环境管理 | venv, uv|

---

## 附录 C：参考文献方法论参考

本流程设计参考了以下科研实践：
- Wikidata 数据模型与链接开放数据原则
- 知识图谱构建最佳实践（Apache Atlas, Google Data Catalog）
- 实体链接评估标准（TAC KBP, MUC）
- 可复现研究数据管理规范（Nature Scientific Data）
